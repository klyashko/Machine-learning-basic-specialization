{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only if there is some absent dataset to download\n",
    "import nltk\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "sys.path.append('.\\\\..\\\\..\\\\..\\\\..')\n",
    "\n",
    "from src.utils.Utils import save_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    "\n",
    "negfeats = [movie_reviews.raw(fileids=[f]) for f in negids]\n",
    "posfeats = [movie_reviews.raw(fileids=[f]) for f in posids]\n",
    "\n",
    "feats = negfeats + posfeats\n",
    "classes = [0] * len(negids) + [1] * len(posids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_1 = Pipeline([('vectorizer', CountVectorizer()), ('classifier', LogisticRegression())])\n",
    "pipeline_2 = Pipeline([('vectorizer', TfidfVectorizer()), ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(pipeline):\n",
    "    score = cross_val_score(pipeline, feats, classes, cv=5)\n",
    "    return score.mean(), score.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task №1 answer [0.84150000000000014, 0.016777961735562549, 0.82100000000000006, 0.0040620192023179784]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ans1_1, ans1_2 = get_score(pipeline_1)\n",
    "ans1_3, ans1_4 = get_score(pipeline_2)\n",
    "\n",
    "save_answer(1, [ans1_1, ans1_2, ans1_3, ans1_4], space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task №2 answer [0.83900000000000008, 0.81299999999999994]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ans2 = []\n",
    "\n",
    "for df in [10, 50]:\n",
    "    pipeline = Pipeline([('vectorizer', CountVectorizer(min_df=df)), ('classifier', LogisticRegression())])\n",
    "    ans2.append(cross_val_score(pipeline, feats, classes, cv=5).mean())\n",
    "\n",
    "save_answer(2, ans2, space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84150000000000014, 0.83250000000000013, 0.77600000000000002]\n",
      "\n",
      "Task №3 answer 0.776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "for clf in [LogisticRegression, LinearSVC, SGDClassifier]:\n",
    "    pipeline = Pipeline([('vectorizer', CountVectorizer()), ('classifier', clf())])\n",
    "    temp.append(cross_val_score(pipeline, feats, classes, cv=5).mean())\n",
    "    \n",
    "print(temp)\n",
    "\n",
    "ans3 = min(temp)\n",
    "save_answer(3, ans3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task №4 answer [0.84099999999999997, 0.83850000000000002]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ans4 = []\n",
    "\n",
    "for sw in [stopwords.words('english'), 'english']:\n",
    "    pipeline = Pipeline([('vectorizer', CountVectorizer(stop_words=sw)), ('classifier', LogisticRegression())])\n",
    "    ans4.append(cross_val_score(pipeline, feats, classes, cv=5).mean())\n",
    "    \n",
    "save_answer(4, ans4, space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task №5 answer [0.85250000000000004, 0.81899999999999995]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_1 = Pipeline([('vectorizer', CountVectorizer(ngram_range=(1, 2))), ('classifier', LogisticRegression())])\n",
    "pipeline_2 = Pipeline([('vectorizer', CountVectorizer(ngram_range=(3, 5), analyzer='char_wb')), ('classifier', LogisticRegression())])\n",
    "\n",
    "ans5_1, _ = get_score(pipeline_1)\n",
    "ans5_2, _ = get_score(pipeline_2)\n",
    "\n",
    "save_answer(5, [ans5_1, ans5_2], space=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
